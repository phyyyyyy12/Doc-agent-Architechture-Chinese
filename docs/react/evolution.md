## 📈 技术演进与思考 (Evolution & Insights)

### 📅 项目里程碑

#### **v2.0 - 垂直领域深度推理 (Current)**

**核心理念：** 放弃“泛用型搜索”，转向“高精度闭环”。

* **反向优化：** 针对内部技术文档场景，主动剔除外部网页搜索工具（Search API），防止互联网噪声稀释内部知识精度。
* **语义对齐：** 强化 Agent 对内部术语和私有架构的理解，确保所有回答均有“据”可查（基于本地 MD 索引）。
* **任务编排升级：** `llm_planner` 引入 JSON 格式的任务列表，支持更复杂的依赖关系分析，避免多轮对话中的逻辑断裂。

#### **v1.0 - 基础 ReAct 架构**

**核心理念：** 实现标准的 `Thought-Action-Observation` 推理循环。

* **做法：** 构建了基础的 `ReActAgent` 和简单的关键词规划器（Simple Planner）。
* **痛点：** * **幻觉风险：** 面对模糊指令时容易调用无关工具，或陷入无效的循环等待。
* **上下文过载：** 未经过滤的工具执行结果（尤其是大量原始日志）直接塞入 Context，导致 Token 迅速耗尽。



---

### 🧠 深度思考：为什么不使用“全能型”Agent？

在开发过程中，我发现**通用型 Agent 在处理私有技术文档时存在明显的“边界模糊”问题**：

1. **外部搜索的副作用：** 当 Agent 找不到内部文档的特定接口时，往往会尝试搜索互联网，返回类似的开源库方案，这在企业级开发中是严重的误导。
2. **噪声即污染：** 原始的调试日志、过长的 MD 文件片段若不经过“语义蒸馏”，会干扰 LLM 的注意力，使其忽略真正的核心参数。
3. **确定性高于灵活性：** 在技术咨询场景，用户更需要“100% 准确的局部信息”而非“50% 准确的全面描述”。
